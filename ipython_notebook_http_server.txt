which http server is running for ipython notebook?

//=== http://ipython.org/ipython-doc/1/interactive/public_server.html
This server uses a two-process kernel architecture based on 
ZeroMQ, as well as Tornado 
for serving HTTP requests. 

By default, a notebook server runs on


//=== http://ipython.org/ipython-doc/1/overview.html#ipythonzmq
ipython has abstracted and extended the notion of a traditional Read-Evaluate-Print Loop (REPL) environment 
by decoupling the evaluation into its own process. We call this process a kernel: 
it receives execution instructions from clients and sends the results back to them.



if you run ipython without any subcommands, you get the traditional single process terminal-based IPython 

all other IPython machinery uses the two-process(client-kernel) model. 
This includes "ipython console, ipython qtconsole, and ipython notebook".


If there is already a kernel running that you want to connect to, 
you can pass the --existing flag which will skip initiating a new kernel and 
connect to the most recent kernel, instead. 

To connect to a specific kernel once you have several kernels running, 
use the %connect_info magic to get the unique connection file, 
which will be something like --existing kernel-19732.json but 
with different numbers which correspond to the Process ID of the kernel.


//=== http://ipython.org/ipython-doc/1/development/messaging.html#messaging
messaging specification for how the various IPython objects interact over a network transport. 
The current implementation uses the ZeroMQ library for messaging within and between hosts.


 The kernel has three sockets that serve the following functions:

stdin: this ROUTER socket is connected to all frontends, and it allows the kernel to request input from the active frontend when raw_input() is called. The frontend that executed the code has a DEALER socket that acts as a ‘virtual keyboard’ for the kernel while this communication is happening (illustrated in the figure by the black outline around the central keyboard). In practice, frontends may display such kernel requests using a special input widget or otherwise indicating that the user is to type input for the kernel instead of normal commands in the frontend.

Shell: this single ROUTER socket allows multiple incoming connections from frontends, and this is the socket where requests for code execution, object information, prompts, etc. are made to the kernel by any frontend. The communication on this socket is a sequence of request/reply actions from each frontend and the kernel.

IOPub: this socket is the ‘broadcast channel’ where the kernel publishes all side effects (stdout, stderr, etc.) as well as the requests coming from any client over the shell socket and its own requests on the stdin socket. There are a number of actions in Python which generate side effects: print() writes to sys.stdout, errors generate tracebacks, etc. Additionally, in a multi-client scenario, we want all frontends to be able to know what each other has sent to the kernel (this can be useful in collaborative scenarios, for example). This socket allows both side effects and the information about communications taking place with one client over the shell channel to be made available to all clients in a uniform manner.



*** Our current implementation uses JSON explicitly as its message format, but this shouldn’t be considered a permanent feature. As we’ve discovered that JSON has non-trivial performance issues due to excessive copying, we may in the future move to a pure pickle-based raw message format. 
*** The default and most common serialization is JSON, but msgpack and pickle are common alternatives.

//===
 IPython’s own implementation of the wire protocol in the IPython.kernel.zmq.session.Session object.


//===
every message is serialized to a sequence of at least six blobs of bytes:

[
  b'u-u-i-d',         # zmq identity(ies)
  b'<IDS|MSG>',       # delimiter
  b'baddad42',        # HMAC signature
  b'{header}',        # serialized header dict
  b'{parent_header}', # serialized parent header dict
  b'{metadata}',      # serialized metadata dict
  b'{content},        # serialized content dict
  b'blob',            # extra raw data buffer(s)
  ...
]


After the delimiter is the HMAC signature of the message, used for authentication. If authentication is disabled, this should be an empty string. By default, the hashing function used for computing these signatures is sha256.


In Python, this is implemented via:

# once:
digester = HMAC(key, digestmod=hashlib.sha256)

# for each message
d = digester.copy()
for serialized_dict in (header, parent, metadata, content):
    d.update(serialized_dict)
signature = d.hexdigest()

After the signature(hash, digest) is the actual message, 
always in four frames of bytes. 
 in the order of header, parent header, metadata, and content. 



//=== execute_request msg.content.'user_xxxx'
The user_ fields deserve a detailed explanation. In the past, IPython had the notion of a prompt string that allowed arbitrary code to be evaluated, and this was put to good use by many in creating prompts that displayed system status, path information, and even more esoteric uses like remote instrument status acquired over the network. But now that IPython has a clean separation between the kernel and the clients, the kernel has no prompt knowledge; prompts are a frontend-side feature, and it should be even possible for different frontends to display different prompts while interacting with the same kernel.

user_variables: If only variables from the user’s namespace are needed, a list of variable names can be passed and a dict with these names as keys and their repr() as values will be returned.
user_expressions: For more complex expressions that require function evaluations, a dict can be provided with string keys and arbitrary python expressions as values. The return message will contain also a dict with the same keys and the repr() of the evaluated expressions as value.


In order to obtain the current execution counter for the purposes of displaying input prompts, frontends simply make an execution request with an empty code string and silent=True.




//=== execute_request_msg.code
To understand how the code field is executed, one must know that 
Python code can be compiled in one of three modes (controlled by the mode argument to the compile() builtin):

single
Valid for a single interactive statement (though the source can contain multiple lines, such as a for loop). When compiled in this mode, the generated bytecode contains special instructions that trigger the calling of sys.displayhook() for any expression in the block that returns a value. This means that a single statement can actually produce multiple calls to sys.displayhook(), if for example it contains a loop where each iteration computes an unassigned expression would generate 10 calls:

for i in range(10):
    i**2
exec
An arbitrary amount of source code, this is how modules are compiled. sys.displayhook() is never implicitly called.
eval
A single expression that returns a value. sys.displayhook() is never implicitly called.




//=== execute_request_msg.code
The code field is split into individual blocks each of which is valid for execution in ‘single’ mode, and then:

If there is only a single block: it is executed in ‘single’ mode.

If there is more than one block:
?if the last one is a single line long, run all but the last in ‘exec’ mode and the very last one in ‘single’ mode. This makes it easy to type simple expressions at the end to see computed values.
?if the last one is no more than two lines long, run all but the last in ‘exec’ mode and the very last one in ‘single’ mode. This makes it easy to type simple expressions at the end to see computed values. - otherwise (last one is also multiline), run all in ‘exec’ mode

otherwise (last one is also multiline), run all in ‘exec’ mode as a single unit.


//=== python introspection
Object information
One of IPython’s most used capabilities is the introspection of Python objects in the user’s namespace, 
typically invoked via the ? and ?? characters (which in reality are shorthands for the %pinfo magic). 

explicitly typing code like x??.


//=== Messages on the stdin ROUTER/DEALER sockets
This is a socket where the request/reply pattern goes in the opposite direction: from the kernel to a single frontend, and its purpose is to allow raw_input and similar operations that read from sys.stdin on the kernel to be fulfilled by the client.

http://ipython.org/ipython-doc/1/development/messaging.html#messaging


*** We do not explicitly try to forward the raw sys.stdin object, because in practice the kernel should behave like an interactive program. When a program is opened on the console, the keyboard effectively takes over the stdin file descriptor, and it can’t be used for raw reading anymore. Since the IPython kernel effectively behaves like a console program (albeit one whose “keyboard” is actually living in a separate process and transported over the zmq connection), raw stdin isn’t expected to be available.



//=== Heartbeat for kernel (detect kernel alive)
it turns out that we can implement a basic heartbeat with pure ZMQ, without using any Python messaging at all.



//=== http://www.tornadoweb.org/en/stable/guide/templates.html
A Tornado template is just HTML (or any other text-based format) with Python control sequences and expressions embedded within the markup:

<html>
   <head>
      <title>{{ title }}</title>
   </head>
   <body>
     <ul>
       {% for item in items %}
         <li>{{ escape(item) }}</li>
       {% end %}
     </ul>
   </body>
 </html> 


Tornado templates support control statements and expressions. Control statements are surrounded by {% and %}, e.g., {% if len(items) > 2 %}. Expressions are surrounded by {{ and }}, e.g., {{ items[0] }}.

control statements
We support if, for, while, and try, all of which are terminated with {% end %}. We also support template inheritance using the extends and block statements,


expression
Expressions can be any Python expression, including function calls. 